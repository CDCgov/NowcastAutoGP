var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"This page provides documentation for all exported functions and types in NowcastAutoGP.jl.","category":"section"},{"location":"api/#Index","page":"API Reference","title":"Index","text":"","category":"section"},{"location":"api/#API","page":"API Reference","title":"API","text":"","category":"section"},{"location":"api/#NowcastAutoGP.TData","page":"API Reference","title":"NowcastAutoGP.TData","text":"TData{D, F}\n\nA container for transformed time series data used in nowcasting models.\n\nType Parameters\n\nD: Type for dates/timestamps (e.g., Date, DateTime)\nF: Type for numeric values, automatically promoted from input types\n\nFields\n\nds::Vector{D}: Vector of dates or timestamps corresponding to observations\ny::Vector{F}: Vector of transformed target values (result of applying transformation)\nvalues::Vector{F}: Vector of original values, converted to common type with y\n\nConstructor\n\nTData(ds, values; transformation)\n\nCreate a TData instance by applying a transformation to the input values.\n\nArguments\n\nds: Vector of dates or timestamps\nvalues: Vector of original numeric values\ntransformation: Function to apply element-wise to values to create y\n\nThe constructor automatically promotes types using promote_type to ensure y and values have compatible numeric types.\n\nExample\n\nusing Dates\n\ndates = [Date(2023, 1, 1), Date(2023, 1, 2), Date(2023, 1, 3)]\nraw_values = [10, 20, 30]\n\n# Apply log transformation\ntdata = TData(dates, raw_values; transformation = log)\n\n# Apply custom transformation\ntdata = TData(dates, raw_values; transformation = x -> (x - mean(raw_values)) / std(raw_values))\n\nValidation\n\nThe constructor ensures that ds and values have the same length and throws an ArgumentError if they don't match.\n\n\n\n\n\n","category":"type"},{"location":"api/#NowcastAutoGP._get_offset-Union{Tuple{Vector{F}}, Tuple{F}} where F<:AbstractFloat","page":"API Reference","title":"NowcastAutoGP._get_offset","text":"_get_offset(values::Vector{F}) where {F <: Real}\n\nInternal function to compute an offset for transformations to ensure numerical stability.\n\n\n\n\n\n","category":"method"},{"location":"api/#NowcastAutoGP._inv_boxcox-Union{Tuple{F}, Tuple{Real, Any, F}} where F","page":"API Reference","title":"NowcastAutoGP._inv_boxcox","text":"_inv_boxcox(λ::Real, offset::F, max_values) where {F}\n\nInternal function to compute the inverse Box-Cox transformation with edge case handling.\n\n\n\n\n\n","category":"method"},{"location":"api/#NowcastAutoGP.create_nowcast_data-Tuple{AbstractMatrix, Vector{Dates.Date}}","page":"API Reference","title":"NowcastAutoGP.create_nowcast_data","text":"create_nowcast_data(nowcasts::AbstractMatrix, dates::Vector{Date}; transformation = y -> y)\n\nCreate nowcast data structures from a matrix of nowcast scenarios.\n\nArguments\n\nnowcasts: A matrix where each column represents one nowcast scenario. The number of rows must match the length of dates.\ndates: A vector of Date objects corresponding to the nowcast time points.\ntransformation: A function to apply to the nowcast values (default: identity).\n\nReturns\n\nA vector of NamedTuples, where each NamedTuple represents one nowcast scenario with fields:\n\nds: The dates vector\ny: The transformed nowcast values\nvalues: The original (untransformed) nowcast values\n\nNotes\n\nThis method converts the matrix to a vector of columns internally and delegates to the vector method.\n\nExample\n\n# Matrix with 3 time points (rows) and 2 scenarios (columns)\nnowcasts = [10.5 9.8; 11.2 10.9; 12.1 11.5]\ndates = [Date(2024,1,1), Date(2024,1,2), Date(2024,1,3)]\nnowcast_data = create_nowcast_data(nowcasts, dates; transformation = log)\n# Returns vector of 2 NamedTuples, each with transformed and original values\n\n\n\n\n\n","category":"method"},{"location":"api/#NowcastAutoGP.create_nowcast_data-Tuple{AbstractVector, Vector{Dates.Date}}","page":"API Reference","title":"NowcastAutoGP.create_nowcast_data","text":"create_nowcast_data(nowcasts::AbstractVector, dates::Vector{Date}; transformation = y -> y)\n\nCreate nowcast data structures from a vector of nowcast scenarios.\n\nArguments\n\nnowcasts: A vector where each element is a vector of nowcast values representing one scenario. All inner vectors must have the same length as dates.\ndates: A vector of Date objects corresponding to the nowcast time points.\ntransformation: A function to apply to the nowcast values (default: identity).\n\nReturns\n\nA vector of NamedTuples, where each NamedTuple represents one nowcast scenario with fields:\n\nds: The dates vector\ny: The transformed nowcast values\nvalues: The original (untransformed) nowcast values\n\nExample\n\n# Two nowcast scenarios for 3 dates\nnowcasts = [[10.5, 11.2, 12.1], [9.8, 10.9, 11.5]]\ndates = [Date(2024,1,1), Date(2024,1,2), Date(2024,1,3)]\nnowcast_data = create_nowcast_data(nowcasts, dates; transformation = log)\n# Returns vector of 2 NamedTuples, each with transformed and original values\n\n\n\n\n\n","category":"method"},{"location":"api/#NowcastAutoGP.create_transformed_data-Tuple{Any, Any}","page":"API Reference","title":"NowcastAutoGP.create_transformed_data","text":"create_transformed_data(ds, values; transformation)\n\nConvenience function to create a TData instance from any iterable inputs of dates/times and values.\n\n\n\n\n\n","category":"method"},{"location":"api/#NowcastAutoGP.forecast-Tuple{AutoGP.GPModel, Any, Int64}","page":"API Reference","title":"NowcastAutoGP.forecast","text":"forecast(model, forecast_dates, forecast_draws::Int)\n\nGenerate forecast samples from a fitted AutoGP model.\n\nArguments\n\nmodel: Fitted AutoGP.GPModel.\nforecast_dates: Vector or range of dates to predict.\nforecast_draws: Number of samples to draw.\n\nKeyword arguments\n\ninv_transformation: Function applied elementwise to map forecasts back to the original scale (default: identity).\nforecast_n_hmc: If nothing, draw from the current model state. If an Int, run that many HMC parameter steps before each draw (default: 1).\n\nReturns\n\nA matrix of samples with size (length(forecast_dates), forecast_draws).\n\n\n\n\n\n","category":"method"},{"location":"api/#NowcastAutoGP.forecast_with_nowcasts-Tuple{AutoGP.GPModel, AbstractVector{<:TData}, Any, Int64}","page":"API Reference","title":"NowcastAutoGP.forecast_with_nowcasts","text":"forecast_with_nowcasts(base_model, nowcasts, forecast_dates, forecast_draws_per_nowcast;\n                      inv_transformation = y -> y, n_mcmc = 0, n_hmc = 0, ess_threshold = 0.0)\n\nGenerate forecasts by conditioning on multiple nowcast scenarios.\n\nArguments\n\nbase_model: Fitted AutoGP.GPModel trained on confirmed (non-nowcast) data.\nnowcasts: Vector of TData scenarios with fields ds, y, and values.\nforecast_dates: Vector or range of dates to predict.\nforecast_draws_per_nowcast: Samples per scenario.\n\nKeyword arguments\n\ninv_transformation: Function applied elementwise to map forecasts back to the original scale (default: identity).\nn_mcmc: Number of MCMC structure steps after adding each nowcast (default: 0). If > 0, n_hmc must also be > 0.\nn_hmc: Number of HMC parameter steps per MCMC step (default: 0). Can be > 0 even if n_mcmc == 0.\ness_threshold: Effective sample size threshold for particle resampling, as a fraction of total particles (default: 0.0).\nforecast_n_hmc: Number of HMC steps to run before each forecast draw (default: 1). If nothing, no HMC steps are taken before forecasting.\n\nReturns\n\nA matrix with size (length(forecast_dates), length(nowcasts) * forecast_draws_per_nowcast).\n\nNotes\n\nEach scenario is added, optionally refined, forecasted, and then removed to restore the model state.\nn_mcmc == 0 && n_hmc > 0 performs parameter-only updates to the particle ensemble; n_mcmc > 0 && n_hmc > 0 performs full MCMC.\nforecast_n_hmc is independent of n_mcmc and n_hmc and controls HMC steps only during forecasting, not during nowcast incorporation.\n\nIf n_mcmc == 0 && n_hmc == 0 && forecast_n_hmc > 0, HMC steps are only taken during forecasting, not during nowcast incorporation.\n\nExample\n\nnowcast_scenarios = [\n    (ds = [Date(2024,1,1), Date(2024,1,2)], y = [10.5, 11.2], values = [10.5, 11.2]),\n    (ds = [Date(2024,1,1), Date(2024,1,2)], y = [9.8, 10.9], values = [9.8, 10.9]),\n]\nforecast_dates = Date(2024,1,1):Day(1):Date(2024,1,10)\nforecasts = forecast_with_nowcasts(base_model, nowcast_scenarios, forecast_dates, 100)\n\n\n\n\n\n","category":"method"},{"location":"api/#NowcastAutoGP.get_transformations-Union{Tuple{F}, Tuple{String, Vector{F}}} where F<:Real","page":"API Reference","title":"NowcastAutoGP.get_transformations","text":"get_transformations(transform_name::String, values::Vector{F}) where {F <: Real}\n\nReturn a tuple of transformation and inverse transformation functions for the specified transformation type.\n\nThis function creates appropriate data transformations for Gaussian Process modeling, where the goal is to transform the input data to make it more suitable for modeling (typically more Gaussian-like) and then provide the inverse transformation to convert predictions back to the original scale.\n\nArguments\n\ntransform_name::String: The name of the transformation to apply. Supported values:\n\"percentage\": For data bounded between 0 and 100 (e.g., percentages, rates)\n\"positive\": For strictly positive data (uses log transformation)\n\"boxcox\": Applies Box-Cox transformation with automatically fitted λ parameter\nvalues::Vector{F}: The input data values used to fit transformation parameters and determine offset\n\nReturns\n\nA tuple (forward_transform, inverse_transform) where:\n\nforward_transform: Function that transforms data from original scale to transformed scale\ninverse_transform: Function that transforms data from transformed scale back to original scale\n\nTransformation Details\n\nPercentage Transformation\n\nUse case: Data bounded between 0 and 100 (percentages, rates)\nForward: y ↦ logit((y + offset) / 100)\nInverse: y ↦ max(logistic(y) * 100 - offset, 0)\nNote: Uses logit/logistic to map [0,100] to (-∞,∞) and back\n\nPositive Transformation\n\nUse case: Strictly positive continuous data\nForward: y ↦ log(y + offset)\nInverse: y ↦ max(exp(y) - offset, 0)\nNote: Log transformation for positive data with offset for numerical stability\n\nBox-Cox Transformation\n\nUse case: General purpose transformation for positive data\nForward: y ↦ BoxCox_λ(y + offset) where λ is automatically fitted\nInverse: Custom inverse function handling edge cases for numerical stability\nNote: Automatically determines optimal λ parameter via maximum likelihood\n\nOffset Calculation\n\nAn offset is automatically calculated using _get_offet(values):\n\nIf minimum value is 0: offset = (minimum positive value) / 2\nOtherwise: offset = 0\nPurpose: Ensures numerical stability and handles boundary cases\n\nExamples\n\n# Percentage data (0-100 range)\nvalues = [10.5, 25.3, 67.8, 89.2]\nforward, inverse = get_transformations(\"percentage\", values)\ntransformed = forward.(values)\nrecovered = inverse.(transformed)\n\n# Strictly positive data\nvalues = [1.2, 3.4, 8.9, 15.6]\nforward, inverse = get_transformations(\"positive\", values)\n\n# General positive data with automatic Box-Cox fitting\nvalues = [0.1, 0.5, 2.3, 5.7, 12.1]\nforward, inverse = get_transformations(\"boxcox\", values)\n\nThrows\n\nAssertionError: If transform_name is not one of the supported transformation types\nAssertionError: Via _get_offet if values is empty or contains negative values\n\nSee Also\n\n_get_offset: Calculates the offset value for numerical stability\n_inv_boxcox: Handles inverse Box-Cox transformation with edge case handling\n\n\n\n\n\n","category":"method"},{"location":"api/#NowcastAutoGP.make_and_fit_model-Tuple{TData}","page":"API Reference","title":"NowcastAutoGP.make_and_fit_model","text":"make_and_fit_model(data; n_particles=8, smc_data_proportion=0.1, n_mcmc=200, n_hmc=50, kwargs...)\n\nCreate and fit a Gaussian Process (GP) model using Sequential Monte Carlo (SMC) sampling.\n\nArguments\n\ndata: A data structure containing the dataset (data.ds) and the target values (data.y).\nn_particles: The number of particles to use in the SMC sampling (default: 8).\nsmc_data_proportion: The proportion of the data to use in each SMC step (default: 0.1).\nn_mcmc: The number of MCMC samples (default: 200).\nn_hmc: The number of HMC samples (default: 50).\nkwargs...: Additional keyword arguments to pass to the AutoGP.fit_smc! function.\n\nReturns\n\nmodel: The fitted GP model.\n\n\n\n\n\n","category":"method"},{"location":"vignettes/tutorial/#Getting-Started-with-NowcastAutoGP","page":"Getting started","title":"Getting Started with NowcastAutoGP","text":"CDC Center for Forecasting and Outbreak Analytics (CFA/CDC)","category":"section"},{"location":"vignettes/tutorial/#Introduction","page":"Getting started","title":"Introduction","text":"This tutorial demonstrates how to use NowcastAutoGP for epidemiological forecasting - making forecasts of future disease activity despite reporting delays making the latest data unreliable. This is a common challenge in public health surveillance where case reports arrive with delays. In this tutorial, we will want to forecast future weekly hospital admissions with confirmed Covid diagnosis despite uncertainty around the eventual value of recent admissions. The reason for the uncertainty is that despite eventually having a record of severe cases arriving in a given week (we call this the reference date), at any given reporting week (we call this the report date) recent reference dates will not have complete data.","category":"section"},{"location":"vignettes/tutorial/#What-is-Nowcasting?","page":"Getting started","title":"What is Nowcasting?","text":"Nowcasting is a form of forecasting aimed at the question: “What will be the eventual value of my time series, given recent reporting?”\n\nFrom our perspective common applications are:\n\nCOVID-19/Influenza/RSV hospital admissions\nCOVID-19/Influenza/RSV Emergency department visits\nReal-time monitoring of reproductive numbers R_t","category":"section"},{"location":"vignettes/tutorial/#The-purpose-of-NowcastAutoGP","page":"Getting started","title":"The purpose of NowcastAutoGP","text":"The time series Gaussian process structure discovery and ensemble forecast package AutoGP.jl is highly impressive, but doesn’t include features for ingesting the kind of data we expect from a signal that needs significant nowcasting to become reliable.\n\nNowcastAutoGP is an extension of AutoGP that uses AutoGP’s incremental inference features to include nowcasting results into the forecasting problem.\n\nWhen forecasting a time series\n\nX_T1T = (X_tT)_t=1T\n\non report date T we split between data on a backwards horizon D where we consider older data “confirmed”\n\nX_T1(T-D) = (X_tT)_t=1(T-D)\n\nthat we don’t expect any further revision to; that is we expect that\n\nX_T1(T-D) = X_infty1(T-D)\n\nThe rest of the data we consider “unconfirmed” X_T(T-D+1)T where we expect potentially significant future revisions and X_T(T-D+1)T neq X_infty(T-D+1)T.\n\nSuppose, we have a nowcasting model that generates K samples that forecast the eventual time series over the uncertain data period the kth sample being\n\nX^(k)_infty(T-D+1)T = (X^(k)_tinfty)_t=(T-D+1)T\n\nfor example by sampling from the posterior distribution. Then we can improve our AutoGP forecasting for the eventual value on reference date f  T by replacing our “naive” forecast distribution:\n\nmathbbP(X_finfty  X_T1(T-D) X_T(T-D+1)T)\n\nwith the nowcast estimate for the uncertain data:\n\nmathbbP(X_finfty mid X_T1(T-D) X_infty(T-D+1)T) = frac1K sum_k mathbbP(X_finfty   X_T1(T-D) X^(k)_infty(T-D+1)T)\n\nThis kind of forecasting is particularly convenient for AutoGP: we can use the standard end-to-end inference for the confirmed data and then batch over the sampled nowcasts using incremental inference.","category":"section"},{"location":"vignettes/tutorial/#Methodology-overview","page":"Getting started","title":"Methodology overview","text":"The main functions we offer for inference and forecasting are:\n\nNowcastAutoGP.make_and_fit_model: This wraps AutoGP functionality to make inference on the stable part of the time series data using sequential Monte Carlo (SMC) over sequences of data ingestion over n_particle SMC particles. Each particle represents a Gaussian process (GP) model for the time series, and at each data ingestion step this particle ensemble can be resampled. Within each SMC particle new possible GP kernel structures and hyperparmeter values are proposed using a specialised MCMC proposal distribution for structural choices (see AutoGP overview for details) and HMC for continuous parameter samples.\nNowcastAutoGP.forecast_with_nowcasts: This batches over proposed nowcasts for recent data, incrementally adding nowcast possible data to make forecasts before removing. The forecast distribution is the batch of forecasts over nowcasts of recent data.","category":"section"},{"location":"vignettes/tutorial/#Using-NowcastAutoGP-with-NHSN-hospitalisation-data","page":"Getting started","title":"Using NowcastAutoGP with NHSN hospitalisation data","text":"","category":"section"},{"location":"vignettes/tutorial/#Loading-dependencies","page":"Getting started","title":"Loading dependencies","text":"using NowcastAutoGP\nusing CairoMakie\nusing Dates, Distributions, Random\nusing CSV, TidierData\n\n# Set random seed for reproducibility\nRandom.seed!(123)\n\n# Set CairoMakie output to png for quarto compat\nCairoMakie.activate!(type = \"png\")","category":"section"},{"location":"vignettes/tutorial/#Loading-Surveillance-Data","page":"Getting started","title":"Loading Surveillance Data","text":"We are going to demonstrate using NowcastAutoGP for forecasting the CDC’s National Healthcare Safety Network (NHSN) reported Covid hospitalisations. We stored a vintaged data set locally.\n\ndatapath = joinpath(@__DIR__(), \"data\", \"vintaged_us_nhsn_data.csv\")\nnhsn_vintage_covid_data = CSV.read(datapath, DataFrame)\n\n# Add time_index column for plotting (1 = minimum date, 2 = next date, etc.)\nunique_dates = sort(unique(nhsn_vintage_covid_data.reference_date))\nd2index(d) = (d - minimum(unique_dates)).value\n\n# Add time_index column using transform!\n\nnhsn_vintage_covid_data = @mutate(nhsn_vintage_covid_data, time_index = d2index(reference_date))\n@glimpse(nhsn_vintage_covid_data)\n\nRows: 4102\nColumns: 8\n.reference_dateDates.Date     2022-10-01, 2022-10-01, 2022-10-01, 2022-10-01, 20\n.report_date   Dates.Date     2025-02-01, 2025-02-08, 2025-02-15, 2025-02-22, 20\n.confirm       Float64        26180.0, 26180.0, 26180.0, 26180.0, 26180.0, 26180\n.max_confirm   Float64        26150.0, 26150.0, 26150.0, 26150.0, 26150.0, 26150\n.lag           Int64          854, 861, 868, 875, 882, 889, 896, 903, 910, 917,\n.multiplier    Float64        0.9988540870893812, 0.9988540870893812, 0.99885408\n.geo_value     InlineStrings.String3us, us, us, us, us, us, us, us, us, us, us,\n.time_index    Int64          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n\nWe see that the most recent report date, especially, is often revised upward eventually.\n\nunique_report_dates = sort(unique(nhsn_vintage_covid_data.report_date))\n# Select every 4th report date, but always include the latest one\nselected_dates = unique_report_dates[1:4:end]\nif unique_report_dates[end] ∉ selected_dates\n    selected_dates = vcat(selected_dates, unique_report_dates[end])\nend\nn_dates = length(selected_dates)\n\n# Create figure\nfig = Figure(size = (800, 600))\nax = Axis(fig[1, 1],\n    xlabel = \"Reference Date\",\n    ylabel = \"NHSN confirmed Covid hospitalisations\",\n    title = \"Reference Date vs Confirm by Report Date (Oct 2024+, all US)\"\n)\n\n# Generate colors - latest date will be black\ncolors = [i == n_dates ? :black : Makie.wong_colors()[mod1(i, 7)] for i in 1:n_dates]\n\n# Plot each selected report date using time_index\nfor (report_date, color) in zip(selected_dates, colors)\n    date_data = @chain nhsn_vintage_covid_data begin\n        @filter(report_date == !!report_date)\n        @arrange(reference_date)\n    end\n\n    scatterlines!(ax, date_data.time_index, date_data.confirm,\n        color = color,\n        label = string(report_date),\n        markersize = 8,\n        linewidth = 2\n    )\nend\n\n# Set up custom x-axis with date strings\n# Get date range for the plot and corresponding indices\nplot_start_date = Date(2024, 10, 1)\nplot_end_date = Date(2025, 10, 1)\n\n# Create tick positions and labels (show every 4 weeks ≈ monthly)\ntick_dates = range(plot_start_date, step = Week(4), length = 13)\n\n# plot_start_date:Week(4):plot_end_date\ntick_indices = d2index.(tick_dates)\ntick_labels = [monthname(d)[1:3] * \"-\" * string(d)[(end-1):end] for d in tick_dates] # Show month-day\n\nax.xticks = (tick_indices, tick_labels)\n\n# Add legend\naxislegend(ax, \"report dates\"; position = :rt)\nxlims!(ax, d2index(plot_start_date), d2index(plot_end_date))\nylims!(ax, 0, 2.2e4)\nresize_to_layout!(fig)\nfig\n\n(Image: )","category":"section"},{"location":"vignettes/tutorial/#Training-data","page":"Getting started","title":"Training data","text":"We know that some recent periods have had bad reporting for NHSN, so we exclude them from the training data.\n\nexclusion_periods = [(Date(2024, 5, 1), Date(2024, 6, 1)),\n    (Date(2024, 10, 1), Date(2024, 11, 15))]\n\ntraining_data = let\n    function in_any_period(d)\n        in_periods = [d >= period[1] && d <= period[2] for period in exclusion_periods]\n        return ~any(in_periods)\n    end\n\n    @chain nhsn_vintage_covid_data begin\n        @filter(in_any_period(reference_date))\n    end\nend\n@glimpse(training_data)\n\nRows: 3772\nColumns: 8\n.reference_dateDates.Date     2022-10-01, 2022-10-01, 2022-10-01, 2022-10-01, 20\n.report_date   Dates.Date     2025-02-01, 2025-02-08, 2025-02-15, 2025-02-22, 20\n.confirm       Float64        26180.0, 26180.0, 26180.0, 26180.0, 26180.0, 26180\n.max_confirm   Float64        26150.0, 26150.0, 26150.0, 26150.0, 26150.0, 26150\n.lag           Int64          854, 861, 868, 875, 882, 889, 896, 903, 910, 917,\n.multiplier    Float64        0.9988540870893812, 0.9988540870893812, 0.99885408\n.geo_value     InlineStrings.String3us, us, us, us, us, us, us, us, us, us, us,\n.time_index    Int64          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,","category":"section"},{"location":"vignettes/tutorial/#Utility-functions","page":"Getting started","title":"Utility functions","text":"We add two utility functions to this tutorial that wrap some NowcastAutoGP capabilities:\n\nA fit_on_data function that does the core workflow on confirmed data:\n\nTransforms the time series into the unconstrained domain. We use an  optimized Box-Cox transform to “normalize” the data.\nRedact some of the recent data, either for poor quality or in  preparation for nowcasting.\nPasses to the make_and_fit_model function.\n\nfunction fit_on_data(report_date;\n    n_redact,\n    max_ahead = 8,\n    date_data = date_data,\n    n_particles = 24,\n    smc_data_proportion = 0.1,\n    n_mcmc = 50, n_hmc = 50)\n\n    # Dates to forecast\n    forecast_dates = [maximum(date_data.reference_date) + Week(k) for k = 0:max_ahead]\n\n    transformation, inv_transformation = get_transformations(\"boxcox\", date_data.confirm)\n    data_to_fit = create_transformed_data(date_data.reference_date[1:(end-n_redact)], date_data.confirm[1:(end-n_redact)]; transformation)\n    model = make_and_fit_model(data_to_fit;\n                                n_particles,\n                                smc_data_proportion,\n                                n_mcmc, n_hmc)\n    return model, forecast_dates, transformation, inv_transformation\nend\n\nWe also give a handy plotting utility for plotting our results.\n\nfunction plot_with_forecasts(forecasts, title::String;\n                            n_ahead,\n                            selected_dates,\n                            colors = colors,\n                            covid_data = nhsn_vintage_covid_data,\n                            plot_start_date = plot_start_date,\n                            plot_end_date = plot_end_date,\n                            y_lim_up = 2.2e4,\n                            size = (1000, 700),\n                            xticks = (tick_indices, tick_labels),\n    )\n\n    fig = Figure(size = size)\n    ax = Axis(fig[1, 1],\n        xlabel = \"Date\",\n        ylabel = \"NHSN confirmed Covid hospitalizations\",\n        title = title\n    )\n\n# Plot forecasts\n    for (report_date, forecast, color) in zip(selected_dates, forecasts, colors)\n\n        date_data = @chain nhsn_vintage_covid_data begin\n            @filter(report_date == !!report_date)\n            @arrange(reference_date)\n        end\n\n        # Plot historical data as light lines\n        scatterlines!(ax, date_data.time_index, date_data.confirm,\n            color = color,\n            linewidth = 2,\n            label = \"$(report_date) data\"\n        )\n\n        # Extract quantiles for forecasts\n        q25 = forecast.iqrs[1:n_ahead, 1]  # 25th percentile\n        median = forecast.iqrs[1:n_ahead, 2]  # 50th percentile (median)\n        q75 = forecast.iqrs[1:n_ahead, 3]  # 75th percentile\n        forecast_indices = d2index.(forecast.dates)[1:n_ahead]\n\n        # Plot uncertainty band (25%-75%)\n        band!(ax, forecast_indices, q25, q75,\n            color = (color, 0.3),\n        )\n\n        # Plot median forecast\n        lines!(ax, forecast_indices, median,\n            color = color,\n            linewidth = 3,\n            linestyle = :dash,\n        )\n    end\n\n    # Add legend\n    axislegend(ax, \"report dates\"; position = :rt)\n    # Limits\n    xlims!(ax, d2index(plot_start_date), d2index(plot_end_date))\n    ylims!(ax, 0, y_lim_up)\n    # Xticks\n    ax.xticks = xticks\n    # Return\n    resize_to_layout!(fig)\n    return fig\nend\n","category":"section"},{"location":"vignettes/tutorial/#Forecasting","page":"Getting started","title":"Forecasting","text":"","category":"section"},{"location":"vignettes/tutorial/#Approach-1:-Forecasting-naively","page":"Getting started","title":"Approach 1: Forecasting naively","text":"Naively, we could just use AutoGP on the latest reported data without considering revisions. This will be biased because we know that typically the most recent data will be revised upwards, but represents a common error when using this data stream.\n\nn_forecasts = 2000\nnaive_forecasts_by_reference_date = map(selected_dates) do report_date\n    # Filter for correct report date\n    date_data = @chain training_data begin\n            @filter(report_date == !!report_date)\n            @arrange(reference_date)\n        end\n    model, forecast_dates, transformation, inv_transformation = fit_on_data(report_date;\n                        n_redact = 0,\n                        date_data = date_data,\n                        )\n    forecasts = forecast(model, forecast_dates, n_forecasts; inv_transformation)\n\n    iqr_forecasts = mapreduce(vcat, eachrow(forecasts)) do fc\n        qs = quantile(fc, [0.25, 0.5, 0.75])\n        qs'\n    end\n\n    return (dates = forecast_dates, forecasts = forecasts, iqrs = iqr_forecasts)\nend\n\nWhen we plot we see that the unrevised data consistently underestimates the eventual counts, which leads to poor forecasting.\n\nplot_with_forecasts(naive_forecasts_by_reference_date, \"Forecasts from Different Report Dates (naive)\";\n                        n_ahead = 4,\n                            selected_dates = selected_dates,\n    )\n\n(Image: )","category":"section"},{"location":"vignettes/tutorial/#Approach-2:-Removing-uncertain-data","page":"Getting started","title":"Approach 2: Removing uncertain data","text":"We note that the problem is mainly with the most recent week of hospitalisation reports. Therefore, another strategy could be to simply redact that week but otherwise leave out forecasting untouched.\n\n\nleave_out_last_forecasts_by_reference_date = map(selected_dates) do report_date\n    date_data = @chain training_data begin\n                @filter(report_date == !!report_date)\n                @arrange(reference_date)\n            end\n    model, forecast_dates, transformation, inv_transformation = fit_on_data(report_date;\n                            n_redact = 1, # Ignore last week of data\n                            date_data = date_data,\n                            )\n    forecasts = forecast(model, forecast_dates, n_forecasts; inv_transformation)\n\n    iqr_forecasts = mapreduce(vcat, eachrow(forecasts)) do fc\n        qs = quantile(fc, [0.25, 0.5, 0.75])\n        qs'\n    end\n\n    return (dates = forecast_dates, forecasts = forecasts, iqrs = iqr_forecasts)\nend\n\nThis looks improved but the forecasts have quite large prediction intervals (we have effectively bumped the forecast horizon by one week).\n\nplot_with_forecasts(leave_out_last_forecasts_by_reference_date, \"Forecasts from Different Report Dates (Leave out last week)\";\n                            n_ahead = 4,\n                            selected_dates = selected_dates,\n    )\n\n(Image: )","category":"section"},{"location":"vignettes/tutorial/#Approach-3:-Forecasting-with-a-simple-nowcast","page":"Getting started","title":"Approach 3: Forecasting with a simple nowcast","text":"Now lets consider a really simple nowcasting model. Over recent vintages we notice that the most recent week gets revised significantly but other weeks are fairly stable. Therefore, we fit the ratio of last weeks report to last weeks eventual reported to a LogNormal. The MLE fit for this was LogNormal(logmean = 0.1, logstd = 0.027).\n\nIn the following example, for each vintage we first fit to all the data except the most recent week (n_redact = 1). Second, we sample a multiplier for the most recent week from the LogNormal distribution 100 times. Third, we use forecast_with_nowcasts to batch 20 forecasts per nowcast signal ontop of the inference done in step one.\n\nThis is a very simple nowcasting approach! Note that cached nowcasts from a more sophisticated approach, such as a full generative model defined by e.g. epinowcast or baselinenowcast, could have been deserialized into this approach.\n\nn_nowcast_samples = 100\nnowcast_forecasts_by_reference_date = map(selected_dates) do report_date\n    # Filter for correct report date\n    date_data = @chain training_data begin\n            @filter(report_date == !!report_date)\n            @arrange(reference_date)\n        end\n    # Fit on all accepted data\n    model, forecast_dates, transformation, inv_transformation = fit_on_data(report_date;\n                        n_redact = 1,\n                        date_data = date_data,\n                        )\n    # Simple nowcast on most recent data where we suspect significant revisions\n    nowcast_samples = [[date_data.confirm[end] * exp(0.1 + randn() * 0.027)] for _ = 1:n_nowcast_samples]\n\n    nowcasts = create_nowcast_data(nowcast_samples, [date_data.reference_date[end]];\n        transformation = transformation)\n\n    forecasts = forecast_with_nowcasts(model, nowcasts, forecast_dates, n_forecasts ÷ n_nowcast_samples ; inv_transformation)\n\n    iqr_forecasts = mapreduce(vcat, eachrow(forecasts)) do fc\n        qs = quantile(fc, [0.25, 0.5, 0.75])\n        qs'\n    end\n\n    return (dates = forecast_dates, forecasts = forecasts, iqrs = iqr_forecasts)\nend\n\nWe see that this significantly improves the forecasting visually.\n\nplot_with_forecasts(nowcast_forecasts_by_reference_date, \"Forecasts from Different Report Dates (Simple Nowcast)\";\n                            n_ahead = 4,\n                            selected_dates = selected_dates,\n    )\n\n(Image: )","category":"section"},{"location":"vignettes/tutorial/#Scoring","page":"Getting started","title":"Scoring","text":"To evaluate the quality of our different forecasting approaches, we use proper scoring rules. A proper scoring rule is a function that assigns a numerical score to a probabilistic forecast, with the property that the score is optimized (in expectation) when the forecast distribution matches the true future data distribution.\n\nThe Continuous Ranked Probability Score (CRPS) is a proper scoring rule that generalizes the absolute error to probabilistic forecasts. For a forecast distribution F(x) = P(X leq x) and observed outcome y, the CRPS is defined as:\n\ntextCRPS(X y) = mathbbEX - y - frac12mathbbEX_1 - X_2\n\nwhere the first term measures the distance between the forecast ensemble and the observation, and the second term measures the spread of the forecast ensemble.\n\nFor a forecast ensemble X = X_1 X_2 ldots X_n, this can be estimated using an empirical sum.\n\nNote: For production forecasting evaluation, we recommend using the comprehensive scoringutils R package, which provides robust implementations of proper scoring rules, forecast evaluation diagnostics, and visualization tools specifically designed for epidemiological forecasting.\n\nLet’s implement a simple CRPS function and functions for getting the mean CRPS score over reporting dates and forecast horizons in order to compare our three forecasting approaches:\n\nfunction crps(y::Real, X::Vector{<:Real})\n    n = length(X)\n\n    # First term: E|X - y|\n    term1 = mean(abs.(X .- y))\n\n    # Second term : E|X_1 - X_2|\n    # Calculate all ordered pairwise differences\n    ordered_pairwise_diffs = [abs(X[i] - X[j]) for i in 1:n for j in (i+1):n]\n    term2 = mean(ordered_pairwise_diffs) #Average value is same as going over all combinations and div by n^2 due to zero diagonal and permutation symmetry\n\n    # CRPS = E|X - y| - 0.5 * E|X_1 - X_2|\n    return term1 - 0.5 * term2\nend\n\nfunction score_forecast(latestdata, forecast_dates, F; max_horizon = 4, data_transform = x -> x)\n        @assert max_horizon <= length(forecast_dates) \"Not enough data to score full horizon\"\n        score_dates = forecast_dates[1:max_horizon]\n        scorable_data = @filter(latestdata, reference_date in !!score_dates)\n        S = mapreduce(+, scorable_data.confirm[1:max_horizon], eachrow(F.forecasts[1:max_horizon, :])) do y, X #Iterate over forecast dates\n            crps(data_transform(y), data_transform.(X))\n        end\n        return S / max_horizon\nend\n\nfunction score_all_forecasts(latestdata, forecasts; max_horizon = 4, data_transform = x -> x)\n    total_score = mapreduce(+, forecasts; init = 0.0) do F # iterate over forecasts\n        forecast_dates = F.dates\n        score_forecast(latestdata, forecast_dates, F; max_horizon, data_transform)\n    end\n    return total_score / length(forecasts)\nend\n\nWe can apply the scoring to each forecasting method, leaving out the most recent forecasts (where we don’t have all the data to score them).\n\nmost_recent_report_date = maximum(selected_dates)\nlatestdata = @filter(nhsn_vintage_covid_data, report_date == !!most_recent_report_date)\n\nscores = map([naive_forecasts_by_reference_date, leave_out_last_forecasts_by_reference_date, nowcast_forecasts_by_reference_date]) do F\n    score_all_forecasts(latestdata, F[1:(end-2)]; data_transform = identity)\nend\n\nThen we can plot these scores as score ratios relative to the simple nowcasting approach.\n\n# Calculate score ratios compared to simple nowcast (baseline)\nbaseline_score = scores[3]  # Simple nowcast score\nscore_ratios = [score / baseline_score for score in scores]\n\n# Create bar plot comparing score ratios\nmethod_names = [\"Naive\", \"Leave Out Last\", \"Simple Nowcast\"]\n\nfig = Figure(size = (600, 400))\nax = Axis(fig[1, 1],\n    xlabel = \"Forecasting Method\",\n    ylabel = \"Score Ratio (lower is better)\",\n    title = \"Forecast Performance: Score Ratios vs Simple Nowcast\"\n)\n\n# Create bar plot with different colors based on performance\nbar_colors = [ratio > 1 ? :red : ratio == 1 ? :green : :blue for ratio in score_ratios]\nbarplot!(ax, 1:3, score_ratios,\n    color = bar_colors,\n    alpha = 0.7,\n    strokewidth = 2,\n    strokecolor = :black)\n\n# Add value labels on top of bars\nfor (i, ratio) in enumerate(score_ratios)\n    text!(ax, i, ratio + 0.02, text = string(round(ratio, digits=2)),\n          align = (:center, :bottom), fontsize = 12)\nend\n\n# Add horizontal line at y=1 for reference (baseline)\nhlines!(ax, [1], color = :black, linestyle = :dash, linewidth = 1)\n\n# Set x-axis labels\nax.xticks = (1:3, method_names)\nax.xticklabelrotation = π/4\n\n# Add some padding to y-limits\ny_max = maximum(score_ratios)\nylims!(ax, 0.8, y_max + 0.1)\n\nresize_to_layout!(fig)\nfig\n\n(Image: Score ratios comparison (relative to simple nowcast baseline))","category":"section"},{"location":"vignettes/tutorial/#Results-and-Interpretation","page":"Getting started","title":"Results and Interpretation","text":"The score ratios clearly show the improvement over this tutorial:\n\nNaive forecasting performs worst - The score ratio shows that  naive forecasting is significantly worse than the nowcast baseline  (ratio > 1), demonstrating that using the most recent reported data  without any adjustment for reporting delays leads to systematically  poor forecast accuracy. This approach fails to account for the known  issue that recent hospitalizations are significantly under-reported.\nLeaving out the last week shows intermediate performance - This  approach achieves a score ratio between the naive method and the  baseline, indicating improved performance over naive forecasting but  still worse than nowcasting. While excluding the most recent (and  most uncertain) week removes problematic reporting delays, it  effectively increases our forecast horizon by one week, leading to  increased uncertainty in predictions.\nSimple nowcasting provides the baseline performance - By  definition, the simple nowcasting approach has a score ratio of 1.0,  serving as our reference point. Even this basic nowcasting approach  (using a simple log-normal multiplier for the most recent week)  substantially outperforms both alternatives, demonstrating the value  of explicitly modelling reporting delays rather than simply ignoring  uncertain data.\n\nThese results support the core motivation for NowcastAutoGP - that combining nowcasting with sophisticated time series modeling can significantly improve forecast accuracy in real-world surveillance scenarios where reporting delays are common. The score ratios provide a clear, interpretable metric showing the improvement that nowcasting provides over simpler alternatives.","category":"section"},{"location":"#NowcastAutoGP.jl","page":"Home","title":"NowcastAutoGP.jl","text":"Centers for Disease Control and Prevention • Center for Forecasting and Outbreak Analytics\n\nAutomated Gaussian Process model discovery for time series data with significant on-going revisions","category":"section"},{"location":"#About-NowcastAutoGP.jl","page":"Home","title":"About NowcastAutoGP.jl","text":"NowcastAutoGP.jl is a Julia package for combining nowcasting of epidemiological time series data with forecasting using an ensemble of Gaussian process (GP) models. The package was developed for the CDC Center for Forecasting and Outbreak Analytics (CFA) to support real-time situational awareness and epidemiological forecasting.\n\nThe basic idea behind this package is to use the incremental fitting capabilities of AutoGP.jl to batch forecasts over probababilistic nowcasts of recent data points. In this way, NowcastAutoGP.jl is able to account for the uncertainty in recent data points that are still being revised, while also leveraging the flexibility and scalability of Gaussian processes for forecasting.\n\nThe main upside of this approach is that its flexibility allows us to be agnostic to the nowcasting method used, as long as it can produce generative samples over the distribution of recent data points; noting that point estimate nowcasts can also be used as one-sample degenerate distributions. However, this does mean that:\n\nThe quality of the nowcasts will impact the quality of the forecasts.\nThe nowcasting and forecasting models are not jointly inferred, which may lead to suboptimal performance compared to a fully Bayesian approach in some circumstances; for example, if the nowcasting model is poorly specified.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"# Standard installation\nusing Pkg\nPkg.add(url=\"https://github.com/CDCgov/NowcastAutoGP.jl\")","category":"section"},{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"Getting started example: A getting started guide demonstrating basic usage for combining forecasting and nowcasting on NHSN covid-19 hospitalization data.","category":"section"},{"location":"#API-Reference-and-Resources","page":"Home","title":"API Reference and Resources","text":"API Documentation","category":"section"}]
}
